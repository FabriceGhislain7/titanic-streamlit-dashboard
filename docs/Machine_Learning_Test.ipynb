{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6869ce2d",
   "metadata": {},
   "source": [
    "# Titanic Dataset Analysis: Machine Learning Predictions\n",
    "\n",
    "## 1. Project Overview\n",
    "\n",
    "### Dataset Description\n",
    "\n",
    "**Overview**\n",
    "\n",
    "Building upon comprehensive exploratory data analysis, this notebook focuses on developing predictive models to determine passenger survival on the Titanic. \n",
    "\n",
    "The data has been split into two groups:\n",
    "- **training set (train.csv)** - Used to build and validate machine learning models\n",
    "- **test set (test.csv)** - Used to evaluate model performance on unseen data\n",
    "\n",
    "The training set provides the outcome **(also known as the \"ground truth\")** for each passenger. Our models will be based on \"features\" like passengers' gender, class, and engineered features derived from data analysis insights. \n",
    "\n",
    "The test set is used to assess how well our model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. Our objective is to predict these outcomes using the trained models.\n",
    "\n",
    "We also include **gender_submission.csv**, a baseline prediction assuming all and only female passengers survive, which serves as our benchmark model.\n",
    "\n",
    "### üéØ ML Objectives\n",
    "\n",
    "This machine learning analysis aims to:\n",
    "\n",
    "1. **Feature Engineering**: Transform raw data into predictive features based on EDA insights\n",
    "2. **Model Development**: Build and compare multiple ML algorithms (Logistic Regression, Random Forest, SVM, etc.)\n",
    "3. **Model Validation**: Use cross-validation and proper train/test methodology to avoid overfitting\n",
    "4. **Performance Optimization**: Tune hyperparameters for optimal predictive accuracy\n",
    "5. **Model Interpretation**: Understand which features drive survival predictions\n",
    "6. **Real-world Application**: Create a deployable model for survival prediction\n",
    "\n",
    "### üìã Data Dictionary\n",
    "\n",
    "| Variable | Definition | Key |\n",
    "|----------|------------|-----|\n",
    "| **survival** | Survival | 0 = No, 1 = Yes |\n",
    "| **pclass** | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| **sex** | Sex | |\n",
    "| **age** | Age in years | |\n",
    "| **sibsp** | # of siblings / spouses aboard the Titanic | |\n",
    "| **parch** | # of parents / children aboard the Titanic | |\n",
    "| **ticket** | Ticket number | |\n",
    "| **fare** | Passenger fare | |\n",
    "| **cabin** | Cabin number | |\n",
    "| **embarked** | Port of Embarkation | C = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n",
    "### üìù Variable Notes\n",
    "\n",
    "**pclass**: A proxy for socio-economic status (SES)\n",
    "- 1st = Upper class\n",
    "- 2nd = Middle class  \n",
    "- 3rd = Lower class\n",
    "\n",
    "**age**: Age is fractional if less than 1. If the age is estimated, it is in the form of xx.5\n",
    "\n",
    "**sibsp**: The dataset defines family relations in this way...\n",
    "- Sibling = brother, sister, stepbrother, stepsister\n",
    "- Spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
    "\n",
    "**parch**: The dataset defines family relations in this way...\n",
    "- Parent = mother, father\n",
    "- Child = daughter, son, stepdaughter, stepson\n",
    "- Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 1: Environment Setup and Library Imports\n",
    "# ================================================================================\n",
    "\n",
    "# Core Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# ML Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Additional Libraries\n",
    "import sys\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 2: Data Loading and Initial Exploration\n",
    "# ================================================================================\n",
    "\n",
    "# Load the datasets\n",
    "print(\"üìä Loading Titanic datasets...\")\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Store passenger IDs for final submission\n",
    "passenger_ids = test_df['PassengerId'].copy()\n",
    "\n",
    "print(f\"‚úÖ Training set loaded: {train_df.shape}\")\n",
    "print(f\"‚úÖ Test set loaded: {test_df.shape}\")\n",
    "\n",
    "# Display basic information\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nTraining Set Shape: {train_df.shape}\")\n",
    "print(f\"Test Set Shape: {test_df.shape}\")\n",
    "\n",
    "print(f\"\\nTarget Variable Distribution:\")\n",
    "print(train_df['Survived'].value_counts())\n",
    "print(f\"Survival Rate: {train_df['Survived'].mean():.3f}\")\n",
    "\n",
    "print(f\"\\nTraining Set Info:\")\n",
    "print(train_df.info())\n",
    "\n",
    "print(f\"\\nFirst 5 rows of training data:\")\n",
    "print(train_df.head())\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 3: Missing Values Analysis\n",
    "# ================================================================================\n",
    "\n",
    "print(\"üîç MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Function to analyze missing values\n",
    "def analyze_missing_values(df, dataset_name):\n",
    "    \"\"\"Comprehensive missing values analysis\"\"\"\n",
    "    missing = df.isnull().sum()\n",
    "    missing_percent = 100 * missing / len(df)\n",
    "    \n",
    "    missing_table = pd.DataFrame({\n",
    "        'Missing Count': missing,\n",
    "        'Missing Percentage': missing_percent\n",
    "    })\n",
    "    missing_table = missing_table[missing_table['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Missing Values:\")\n",
    "    print(missing_table)\n",
    "    \n",
    "    return missing_table\n",
    "\n",
    "# Analyze missing values in both datasets\n",
    "train_missing = analyze_missing_values(train_df, \"TRAINING SET\")\n",
    "test_missing = analyze_missing_values(test_df, \"TEST SET\")\n",
    "\n",
    "# Visualize missing values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Training set missing values\n",
    "train_missing_viz = train_df.isnull().sum()\n",
    "train_missing_viz = train_missing_viz[train_missing_viz > 0].sort_values(ascending=False)\n",
    "axes[0].bar(train_missing_viz.index, train_missing_viz.values, color='coral')\n",
    "axes[0].set_title('Missing Values - Training Set')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Test set missing values\n",
    "test_missing_viz = test_df.isnull().sum()\n",
    "test_missing_viz = test_missing_viz[test_missing_viz > 0].sort_values(ascending=False)\n",
    "axes[1].bar(test_missing_viz.index, test_missing_viz.values, color='lightblue')\n",
    "axes[1].set_title('Missing Values - Test Set')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 4: Feature Engineering Functions\n",
    "# ================================================================================\n",
    "\n",
    "print(\"üîß FEATURE ENGINEERING SETUP\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def extract_title(name):\n",
    "    \"\"\"Extract title from passenger name\"\"\"\n",
    "    title = name.split(',')[1].split('.')[0].strip()\n",
    "    # Group rare titles\n",
    "    title_mapping = {\n",
    "        'Mr': 'Mr',\n",
    "        'Miss': 'Miss', \n",
    "        'Mrs': 'Mrs',\n",
    "        'Master': 'Master',\n",
    "        'Dr': 'Rare',\n",
    "        'Rev': 'Rare',\n",
    "        'Major': 'Rare',\n",
    "        'Col': 'Rare',\n",
    "        'Capt': 'Rare',\n",
    "        'Countess': 'Rare',\n",
    "        'Don': 'Rare',\n",
    "        'Dona': 'Rare',\n",
    "        'Jonkheer': 'Rare',\n",
    "        'Lady': 'Rare',\n",
    "        'Mlle': 'Miss',\n",
    "        'Mme': 'Mrs',\n",
    "        'Ms': 'Miss',\n",
    "        'Sir': 'Rare'\n",
    "    }\n",
    "    return title_mapping.get(title, 'Rare')\n",
    "\n",
    "def create_family_features(df):\n",
    "    \"\"\"Create family-related features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Family size\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    \n",
    "    # Family size categories\n",
    "    df['FamilySizeGroup'] = 'Medium'\n",
    "    df.loc[df['FamilySize'] == 1, 'FamilySizeGroup'] = 'Alone'\n",
    "    df.loc[df['FamilySize'] >= 5, 'FamilySizeGroup'] = 'Large'\n",
    "    \n",
    "    # Is alone\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_age_features(df):\n",
    "    \"\"\"Create age-related features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Age groups\n",
    "    df['AgeGroup'] = 'Adult'\n",
    "    df.loc[df['Age'] <= 16, 'AgeGroup'] = 'Child'\n",
    "    df.loc[df['Age'] >= 60, 'AgeGroup'] = 'Senior'\n",
    "    \n",
    "    # Is child\n",
    "    df['IsChild'] = (df['Age'] <= 16).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_fare_features(df):\n",
    "    \"\"\"Create fare-related features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Fare per person\n",
    "    df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n",
    "    \n",
    "    # Fare categories based on quantiles\n",
    "    fare_bins = [0, 7.91, 14.454, 31, np.inf]\n",
    "    fare_labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "    df['FareGroup'] = pd.cut(df['Fare'], bins=fare_bins, labels=fare_labels, include_lowest=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_cabin_features(df):\n",
    "    \"\"\"Create cabin-related features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Has cabin\n",
    "    df['HasCabin'] = df['Cabin'].notna().astype(int)\n",
    "    \n",
    "    # Cabin deck (first letter)\n",
    "    df['CabinDeck'] = df['Cabin'].str[0]\n",
    "    df['CabinDeck'] = df['CabinDeck'].fillna('Unknown')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_ticket_features(df):\n",
    "    \"\"\"Create ticket-related features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ticket length\n",
    "    df['TicketLength'] = df['Ticket'].str.len()\n",
    "    \n",
    "    # Has numeric ticket\n",
    "    df['HasNumericTicket'] = df['Ticket'].str.isdigit().astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Feature engineering functions defined!\")\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 5: Data Preprocessing Pipeline\n",
    "# ================================================================================\n",
    "\n",
    "def preprocess_data(df, is_training=True):\n",
    "    \"\"\"\n",
    "    Comprehensive data preprocessing pipeline\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîÑ Preprocessing {'training' if is_training else 'test'} data...\")\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Extract titles\n",
    "    df['Title'] = df['Name'].apply(extract_title)\n",
    "    \n",
    "    # 2. Create family features\n",
    "    df = create_family_features(df)\n",
    "    \n",
    "    # 3. Handle missing Ages using median by Title and Pclass\n",
    "    age_median = df.groupby(['Title', 'Pclass'])['Age'].median()\n",
    "    for title in df['Title'].unique():\n",
    "        for pclass in df['Pclass'].unique():\n",
    "            mask = (df['Title'] == title) & (df['Pclass'] == pclass) & df['Age'].isna()\n",
    "            if mask.sum() > 0:\n",
    "                median_age = age_median.get((title, pclass))\n",
    "                if pd.notna(median_age):\n",
    "                    df.loc[mask, 'Age'] = median_age\n",
    "                else:\n",
    "                    # Fallback to overall median for title\n",
    "                    overall_median = df[df['Title'] == title]['Age'].median()\n",
    "                    if pd.notna(overall_median):\n",
    "                        df.loc[mask, 'Age'] = overall_median\n",
    "                    else:\n",
    "                        df.loc[mask, 'Age'] = df['Age'].median()\n",
    "    \n",
    "    # 4. Create age features\n",
    "    df = create_age_features(df)\n",
    "    \n",
    "    # 5. Handle missing Embarked (mode)\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "    \n",
    "    # 6. Handle missing Fare (median by Pclass)\n",
    "    if df['Fare'].isna().sum() > 0:\n",
    "        fare_median = df.groupby('Pclass')['Fare'].median()\n",
    "        for pclass in df['Pclass'].unique():\n",
    "            mask = (df['Pclass'] == pclass) & df['Fare'].isna()\n",
    "            if mask.sum() > 0:\n",
    "                df.loc[mask, 'Fare'] = fare_median[pclass]\n",
    "    \n",
    "    # 7. Create fare features\n",
    "    df = create_fare_features(df)\n",
    "    \n",
    "    # 8. Create cabin features\n",
    "    df = create_cabin_features(df)\n",
    "    \n",
    "    # 9. Create ticket features\n",
    "    df = create_ticket_features(df)\n",
    "    \n",
    "    # 10. Drop original columns that are no longer needed\n",
    "    columns_to_drop = ['Name', 'Ticket', 'Cabin']\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "    \n",
    "    print(f\"‚úÖ Preprocessing complete. Final shape: {df.shape}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply preprocessing to both datasets\n",
    "print(\"üîÑ APPLYING PREPROCESSING PIPELINE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "train_processed = preprocess_data(train_df, is_training=True)\n",
    "test_processed = preprocess_data(test_df, is_training=False)\n",
    "\n",
    "print(f\"\\nProcessed Training Set Shape: {train_processed.shape}\")\n",
    "print(f\"Processed Test Set Shape: {test_processed.shape}\")\n",
    "\n",
    "# Check for remaining missing values\n",
    "print(f\"\\nRemaining missing values in training set:\")\n",
    "print(train_processed.isnull().sum().sum())\n",
    "\n",
    "print(f\"\\nRemaining missing values in test set:\")\n",
    "print(test_processed.isnull().sum().sum())\n",
    "\n",
    "# Display processed data sample\n",
    "print(f\"\\nProcessed training data sample:\")\n",
    "print(train_processed.head())\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 6: Feature Analysis and Selection\n",
    "# ================================================================================\n",
    "\n",
    "print(\"üìä FEATURE ANALYSIS AND SELECTION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Separate features and target\n",
    "X_train_processed = train_processed.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y_train = train_processed['Survived']\n",
    "\n",
    "print(f\"Features shape: {X_train_processed.shape}\")\n",
    "print(f\"Target shape: {y_train.shape}\")\n",
    "\n",
    "# Analyze categorical vs numerical features\n",
    "categorical_features = X_train_processed.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_features = X_train_processed.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"\\nCategorical features ({len(categorical_features)}): {categorical_features}\")\n",
    "print(f\"Numerical features ({len(numerical_features)}): {numerical_features}\")\n",
    "\n",
    "# Correlation analysis for numerical features\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = X_train_processed[numerical_features].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Correlation Matrix - Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance using mutual information\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Encode categorical variables for mutual information\n",
    "X_encoded = X_train_processed.copy()\n",
    "le_dict = {}\n",
    "\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))\n",
    "    le_dict[col] = le\n",
    "\n",
    "# Calculate mutual information\n",
    "mi_scores = mutual_info_classif(X_encoded, y_train)\n",
    "mi_scores = pd.Series(mi_scores, index=X_encoded.columns).sort_values(ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "mi_scores.plot(kind='barh', color='skyblue')\n",
    "plt.title('Feature Importance (Mutual Information)')\n",
    "plt.xlabel('Mutual Information Score')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 most important features:\")\n",
    "print(mi_scores.head(10))\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 7: Data Encoding and Scaling\n",
    "# ================================================================================\n",
    "\n",
    "print(\"üî¢ DATA ENCODING AND SCALING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def encode_features(X_train, X_test, categorical_features):\n",
    "    \"\"\"\n",
    "    Encode categorical features using one-hot encoding\n",
    "    \"\"\"\n",
    "    X_train_encoded = X_train.copy()\n",
    "    X_test_encoded = X_test.copy()\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    for feature in categorical_features:\n",
    "        # Get all unique values from both train and test\n",
    "        all_categories = list(set(X_train[feature].unique()) | set(X_test[feature].unique()))\n",
    "        \n",
    "        # Create dummy variables\n",
    "        train_dummies = pd.get_dummies(X_train[feature], prefix=feature)\n",
    "        test_dummies = pd.get_dummies(X_test[feature], prefix=feature)\n",
    "        \n",
    "        # Ensure both have same columns\n",
    "        for category in all_categories:\n",
    "            col_name = f\"{feature}_{category}\"\n",
    "            if col_name not in train_dummies.columns:\n",
    "                train_dummies[col_name] = 0\n",
    "            if col_name not in test_dummies.columns:\n",
    "                test_dummies[col_name] = 0\n",
    "        \n",
    "        # Sort columns to ensure same order\n",
    "        train_dummies = train_dummies.reindex(sorted(train_dummies.columns), axis=1)\n",
    "        test_dummies = test_dummies.reindex(sorted(test_dummies.columns), axis=1)\n",
    "        \n",
    "        # Drop original feature and add dummies\n",
    "        X_train_encoded = X_train_encoded.drop(feature, axis=1)\n",
    "        X_test_encoded = X_test_encoded.drop(feature, axis=1)\n",
    "        \n",
    "        X_train_encoded = pd.concat([X_train_encoded, train_dummies], axis=1)\n",
    "        X_test_encoded = pd.concat([X_test_encoded, test_dummies], axis=1)\n",
    "    \n",
    "    return X_train_encoded, X_test_encoded\n",
    "\n",
    "# Prepare test features (remove PassengerId)\n",
    "X_test_processed = test_processed.drop('PassengerId', axis=1)\n",
    "\n",
    "# Encode features\n",
    "X_train_encoded, X_test_encoded = encode_features(\n",
    "    X_train_processed, X_test_processed, categorical_features\n",
    ")\n",
    "\n",
    "print(f\"Encoded training features shape: {X_train_encoded.shape}\")\n",
    "print(f\"Encoded test features shape: {X_test_encoded.shape}\")\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Identify numerical columns in encoded data\n",
    "numerical_cols_encoded = X_train_encoded.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols_encoded = [col for col in X_train_encoded.columns if col not in numerical_cols_encoded]\n",
    "\n",
    "print(f\"Numerical columns to scale: {len(numerical_cols_encoded)}\")\n",
    "print(f\"Categorical (dummy) columns: {len(categorical_cols_encoded)}\")\n",
    "\n",
    "# Scale only numerical features\n",
    "X_train_scaled = X_train_encoded.copy()\n",
    "X_test_scaled = X_test_encoded.copy()\n",
    "\n",
    "if len(numerical_cols_encoded) > 0:\n",
    "    X_train_scaled[numerical_cols_encoded] = scaler.fit_transform(X_train_encoded[numerical_cols_encoded])\n",
    "    X_test_scaled[numerical_cols_encoded] = scaler.transform(X_test_encoded[numerical_cols_encoded])\n",
    "\n",
    "print(f\"‚úÖ Feature encoding and scaling complete!\")\n",
    "print(f\"Final training features shape: {X_train_scaled.shape}\")\n",
    "print(f\"Final test features shape: {X_test_scaled.shape}\")\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 8: Train-Validation Split\n",
    "# ================================================================================\n",
    "\n",
    "print(\"üîÑ CREATING TRAIN-VALIDATION SPLIT\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Split the training data into train and validation sets\n",
    "X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(\n",
    "    X_train_scaled, y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train_final.shape}\")\n",
    "print(f\"Validation set: {X_val_final.shape}\")\n",
    "print(f\"Training target distribution:\")\n",
    "print(f\"  Survived: {y_train_final.sum()} ({y_train_final.mean():.3f})\")\n",
    "print(f\"  Not Survived: {len(y_train_final) - y_train_final.sum()} ({1 - y_train_final.mean():.3f})\")\n",
    "\n",
    "print(f\"Validation target distribution:\")\n",
    "print(f\"  Survived: {y_val_final.sum()} ({y_val_final.mean():.3f})\")\n",
    "print(f\"  Not Survived: {len(y_val_final) - y_val_final.sum()} ({1 - y_val_final.mean():.3f})\")\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 9: Model Definition and Training\n",
    "# ================================================================================\n",
    "\n",
    "print(\"ü§ñ MODEL DEFINITION AND TRAINING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define models to test\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model, X_train, X_val, y_train, y_val, model_name):\n",
    "    \"\"\"\n",
    "    Train and evaluate a model\n",
    "    \"\"\"\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate probabilities for ROC-AUC\n",
    "    try:\n",
    "        y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_val_proba)\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_precision = precision_score(y_val, y_val_pred)\n",
    "    val_recall = recall_score(y_val, y_val_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred)\n",
    "    \n",
    "    results = {\n",
    "        'Model': model_name,\n",
    "        'Train Accuracy': train_accuracy,\n",
    "        'Val Accuracy': val_accuracy,\n",
    "        'Precision': val_precision,\n",
    "        'Recall': val_recall,\n",
    "        'F1 Score': val_f1,\n",
    "        'ROC-AUC': roc_auc\n",
    "    }\n",
    "    \n",
    "    return results, model\n",
    "\n",
    "# Train and evaluate all models\n",
    "results_list = []\n",
    "trained_models = {}\n",
    "\n",
    "print(\"Training and evaluating models...\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîÑ Training {name}...\")\n",
    "    \n",
    "    results, trained_model = evaluate_model(\n",
    "        model, X_train_final, X_val_final, y_train_final, y_val_final, name\n",
    "    )\n",
    "    \n",
    "    results_list.append(results)\n",
    "    trained_models[name] = trained_model\n",
    "    \n",
    "    print(f\"‚úÖ {name} - Val Accuracy: {results['Val Accuracy']:.4f}\")\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df = results_df.sort_values('Val Accuracy', ascending=False)\n",
    "\n",
    "print(f\"\\nüìä MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(results_df.round(4))\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 10: Cross-Validation Analysis\n",
    "# ================================================================================\n",
    "\n",
    "print(\"üîç CROSS-VALIDATION ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Perform cross-validation for more robust evaluation\n",
    "cv_scores = {}\n",
    "cv_folds = 5\n",
    "\n",
    "print(f\"Performing {cv_folds}-fold cross-validation...\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîÑ CV for {name}...\")\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_score = cross_val_score(\n",
    "        model, X_train_scaled, y_train, \n",
    "        cv=StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42),\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    \n",
    "    cv_scores[name] = {\n",
    "        'Mean CV Score': cv_score.mean(),\n",
    "        'Std CV Score': cv_score.std(),\n",
    "        'CV Scores': cv_score\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ {name} - CV Score: {cv_score.mean():.4f} (+/- {cv_score.std() * 2:.4f})\")\n",
    "\n",
    "# Create CV results DataFrame\n",
    "cv_results = []\n",
    "for name, scores in cv_scores.items():\n",
    "    cv_results.append({\n",
    "        'Model': name,\n",
    "        'Mean CV Score': scores['Mean CV Score'],\n",
    "        'Std CV Score': scores['Std CV Score']\n",
    "    })\n",
    "\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "cv_results_df = cv_results_df.sort_values('Mean CV Score', ascending=False)\n",
    "\n",
    "print(f\"\\nüìä CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(cv_results_df.round(4))\n",
    "\n",
    "# Visualize CV results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.errorbar(cv_results_df['Model'], cv_results_df['Mean CV Score'], \n",
    "             yerr=cv_results_df['Std CV Score'], fmt='o', capsize=5)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Cross-Validation Accuracy')\n",
    "plt.title('Model Performance with Cross-Validation')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 11: Hyperparameter Tuning\n",
    "# ================================================================================\n",
    "\n",
    "print(\"üéõÔ∏è HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Select top 3 models for hyperparameter tuning\n",
    "top_models = cv_results_df.head(3)['Model'].tolist()\n",
    "print(f\"Tuning hyperparameters for top models: {top_models}\")\n",
    "\n",
    "# Define parameter grids\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [5, 10, 15, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "tuned_models = {}\n",
    "tuning_results = []\n",
    "\n",
    "for model_name in top_models:\n",
    "    if model_name in param_grids:\n",
    "        print(f\"‚úÖ {model_name} - Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "        print(f\"   Validation Accuracy: {tuned_accuracy:.4f}\")\n",
    "        print(f\"   Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Display tuning results\n",
    "print(f\"\\nüìä HYPERPARAMETER TUNING RESULTS\")\n",
    "print(\"=\"*50)\n",
    "for result in tuning_results:\n",
    "    print(f\"\\n{result['Model']}:\")\n",
    "    print(f\"  Best CV Score: {result['Best Score (CV)']:.4f}\")\n",
    "    print(f\"  Validation Accuracy: {result['Validation Accuracy']:.4f}\")\n",
    "    print(f\"  Best Parameters: {result['Best Parameters']}\")\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 12: Model Ensemble and Final Model Selection\n",
    "# ================================================================================\n",
    "\n",
    "print(\"üèÜ MODEL ENSEMBLE AND FINAL SELECTION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create ensemble model with top performers\n",
    "ensemble_models = []\n",
    "ensemble_names = []\n",
    "\n",
    "# Select best tuned models\n",
    "for result in tuning_results:\n",
    "    model_name = result['Model']\n",
    "    if model_name in tuned_models:\n",
    "        ensemble_models.append((model_name.lower().replace(' ', '_'), tuned_models[model_name]))\n",
    "        ensemble_names.append(model_name)\n",
    "\n",
    "print(f\"Creating ensemble with: {ensemble_names}\")\n",
    "\n",
    "# Create voting classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=ensemble_models,\n",
    "    voting='soft'  # Use probability-based voting\n",
    ")\n",
    "\n",
    "# Train ensemble\n",
    "print(\"\\nüîÑ Training ensemble model...\")\n",
    "voting_clf.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Evaluate ensemble\n",
    "y_val_pred_ensemble = voting_clf.predict(X_val_final)\n",
    "ensemble_accuracy = accuracy_score(y_val_final, y_val_pred_ensemble)\n",
    "ensemble_precision = precision_score(y_val_final, y_val_pred_ensemble)\n",
    "ensemble_recall = recall_score(y_val_final, y_val_pred_ensemble)\n",
    "ensemble_f1 = f1_score(y_val_final, y_val_pred_ensemble)\n",
    "\n",
    "print(f\"‚úÖ Ensemble Model Performance:\")\n",
    "print(f\"   Validation Accuracy: {ensemble_accuracy:.4f}\")\n",
    "print(f\"   Precision: {ensemble_precision:.4f}\")\n",
    "print(f\"   Recall: {ensemble_recall:.4f}\")\n",
    "print(f\"   F1 Score: {ensemble_f1:.4f}\")\n",
    "\n",
    "# Compare with individual models\n",
    "print(f\"\\nüìä FINAL MODEL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "final_comparison = []\n",
    "\n",
    "# Add individual tuned models\n",
    "for result in tuning_results:\n",
    "    final_comparison.append({\n",
    "        'Model': result['Model'] + ' (Tuned)',\n",
    "        'Validation Accuracy': result['Validation Accuracy'],\n",
    "        'Type': 'Individual'\n",
    "    })\n",
    "\n",
    "# Add ensemble\n",
    "final_comparison.append({\n",
    "    'Model': 'Ensemble (Voting)',\n",
    "    'Validation Accuracy': ensemble_accuracy,\n",
    "    'Type': 'Ensemble'\n",
    "})\n",
    "\n",
    "final_df = pd.DataFrame(final_comparison)\n",
    "final_df = final_df.sort_values('Validation Accuracy', ascending=False)\n",
    "print(final_df)\n",
    "\n",
    "# Select best model\n",
    "best_model_row = final_df.iloc[0]\n",
    "best_model_name = best_model_row['Model']\n",
    "best_accuracy = best_model_row['Validation Accuracy']\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "print(f\"   Validation Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 13: Feature Importance Analysis\n",
    "# ================================================================================\n",
    "\n",
    "print(\"üìä FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get feature importance from the best performing individual model\n",
    "# Use Random Forest for feature importance (most interpretable)\n",
    "if 'Random Forest' in tuned_models:\n",
    "    rf_model = tuned_models['Random Forest']\n",
    "elif 'Random Forest' in trained_models:\n",
    "    rf_model = trained_models['Random Forest']\n",
    "else:\n",
    "    # Train a new Random Forest for feature importance\n",
    "    rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    rf_model.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train_final.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Top 15 Most Important Features:\")\n",
    "print(feature_importance.head(15))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['Importance'], color='skyblue')\n",
    "plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 15 Feature Importance (Random Forest)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze feature groups\n",
    "feature_groups = {\n",
    "    'Personal': ['Sex', 'Age', 'Title'],\n",
    "    'Family': ['FamilySize', 'IsAlone', 'SibSp', 'Parch'],\n",
    "    'Economic': ['Pclass', 'Fare', 'FareGroup', 'FarePerPerson'],\n",
    "    'Location': ['Embarked', 'CabinDeck', 'HasCabin'],\n",
    "    'Other': ['TicketLength', 'HasNumericTicket']\n",
    "}\n",
    "\n",
    "group_importance = {}\n",
    "for group, features in feature_groups.items():\n",
    "    group_features = [f for f in features if any(f in col for col in feature_importance['Feature'])]\n",
    "    if group_features:\n",
    "        # Sum importance of features containing group feature names\n",
    "        importance_sum = 0\n",
    "        for feature in group_features:\n",
    "            matching_cols = [col for col in feature_importance['Feature'] if feature in col]\n",
    "            importance_sum += feature_importance[feature_importance['Feature'].isin(matching_cols)]['Importance'].sum()\n",
    "        group_importance[group] = importance_sum\n",
    "\n",
    "# Plot group importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "groups = list(group_importance.keys())\n",
    "importances = list(group_importance.values())\n",
    "plt.bar(groups, importances, color='lightcoral')\n",
    "plt.xlabel('Feature Groups')\n",
    "plt.ylabel('Total Importance')\n",
    "plt.title('Feature Importance by Groups')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature Group Importance:\")\n",
    "for group, importance in sorted(group_importance.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {group}: {importance:.4f}\")\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 14: Model Evaluation and Confusion Matrix\n",
    "# ================================================================================\n",
    "\n",
    "print(\"üìà DETAILED MODEL EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Select final model for evaluation\n",
    "if best_model_name == 'Ensemble (Voting)':\n",
    "    final_model = voting_clf\n",
    "    model_for_eval = voting_clf\n",
    "else:\n",
    "    # Find the corresponding tuned model\n",
    "    model_key = best_model_name.replace(' (Tuned)', '')\n",
    "    final_model = tuned_models[model_key]\n",
    "    model_for_eval = final_model\n",
    "\n",
    "# Make predictions\n",
    "y_val_pred_final = model_for_eval.predict(X_val_final)\n",
    "y_val_proba_final = model_for_eval.predict_proba(X_val_final)[:, 1]\n",
    "\n",
    "# Calculate all metrics\n",
    "final_accuracy = accuracy_score(y_val_final, y_val_pred_final)\n",
    "final_precision = precision_score(y_val_final, y_val_pred_final)\n",
    "final_recall = recall_score(y_val_final, y_val_pred_final)\n",
    "final_f1 = f1_score(y_val_final, y_val_pred_final)\n",
    "final_roc_auc = roc_auc_score(y_val_final, y_val_proba_final)\n",
    "\n",
    "print(f\"FINAL MODEL PERFORMANCE ({best_model_name}):\")\n",
    "print(f\"  Accuracy:  {final_accuracy:.4f}\")\n",
    "print(f\"  Precision: {final_precision:.4f}\")\n",
    "print(f\"  Recall:    {final_recall:.4f}\")\n",
    "print(f\"  F1 Score:  {final_f1:.4f}\")\n",
    "print(f\"  ROC-AUC:   {final_roc_auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val_final, y_val_pred_final)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Confusion Matrix\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Not Survived', 'Survived'],\n",
    "            yticklabels=['Not Survived', 'Survived'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "# Plot 2: ROC Curve\n",
    "plt.subplot(1, 3, 2)\n",
    "fpr, tpr, _ = roc_curve(y_val_final, y_val_proba_final)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {final_roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Plot 3: Prediction Distribution\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(y_val_proba_final[y_val_final == 0], bins=20, alpha=0.7, label='Not Survived', color='red')\n",
    "plt.hist(y_val_proba_final[y_val_final == 1], bins=20, alpha=0.7, label='Survived', color='blue')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Prediction Probability Distribution')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(f\"\\nCLASSIFICATION REPORT:\")\n",
    "print(\"=\"*40)\n",
    "print(classification_report(y_val_final, y_val_pred_final, \n",
    "                          target_names=['Not Survived', 'Survived']))\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 15: Cross-Validation on Final Model\n",
    "# ================================================================================\n",
    "\n",
    "print(\"üîÑ FINAL MODEL CROSS-VALIDATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Perform comprehensive cross-validation on final model\n",
    "cv_scores_final = cross_val_score(\n",
    "    model_for_eval, X_train_scaled, y_train, \n",
    "    cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42),\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(f\"10-Fold Cross-Validation Results for {best_model_name}:\")\n",
    "print(f\"  Mean Accuracy: {cv_scores_final.mean():.4f}\")\n",
    "print(f\"  Std Deviation: {cv_scores_final.std():.4f}\")\n",
    "print(f\"  95% Confidence Interval: {cv_scores_final.mean():.4f} ¬± {1.96 * cv_scores_final.std():.4f}\")\n",
    "\n",
    "# Plot CV scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(cv_scores_final, labels=[best_model_name])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Cross-Validation Score Distribution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nIndividual CV Scores:\")\n",
    "for i, score in enumerate(cv_scores_final, 1):\n",
    "    print(f\"  Fold {i:2d}: {score:.4f}\")\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 16: Learning Curves\n",
    "# ================================================================================\n",
    "\n",
    "print(\"üìà LEARNING CURVES ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Generate learning curves\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    model_for_eval, X_train_scaled, y_train,\n",
    "    cv=5, n_jobs=-1, \n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Calculate mean and std\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training Score')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "plt.plot(train_sizes, val_mean, 'o-', color='red', label='Validation Score')\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='red')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Learning Curves')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot bias-variance analysis\n",
    "plt.subplot(1, 2, 2)\n",
    "bias = train_mean - val_mean\n",
    "plt.plot(train_sizes, bias, 'o-', color='green', label='Bias (Train - Val)')\n",
    "plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Bias')\n",
    "plt.title('Bias Analysis')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze results\n",
    "final_bias = bias[-1]\n",
    "final_variance = val_std[-1]\n",
    "\n",
    "print(f\"Learning Curve Analysis:\")\n",
    "print(f\"  Final Training Score: {train_mean[-1]:.4f} ¬± {train_std[-1]:.4f}\")\n",
    "print(f\"  Final Validation Score: {val_mean[-1]:.4f} ¬± {val_std[-1]:.4f}\")\n",
    "print(f\"  Bias (Underfitting): {final_bias:.4f}\")\n",
    "print(f\"  Variance (Overfitting): {final_variance:.4f}\")\n",
    "\n",
    "if final_bias > 0.05:\n",
    "    print(\"  ‚ö†Ô∏è  Model may be underfitting (high bias)\")\n",
    "elif final_bias < -0.05:\n",
    "    print(\"  ‚ö†Ô∏è  Model may be overfitting (negative bias)\")\n",
    "else:\n",
    "    print(\"  ‚úÖ Model bias is acceptable\")\n",
    "\n",
    "if final_variance > 0.05:\n",
    "    print(\"  ‚ö†Ô∏è  Model has high variance\")\n",
    "else:\n",
    "    print(\"  ‚úÖ Model variance is acceptable\")\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 17: Make Predictions on Test Set\n",
    "# ================================================================================\n",
    "\n",
    "print(\"üéØ MAKING PREDICTIONS ON TEST SET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Train final model on entire training set\n",
    "print(f\"Training final model on entire training set...\")\n",
    "model_for_eval.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "print(f\"Making predictions on test set...\")\n",
    "test_predictions = model_for_eval.predict(X_test_scaled)\n",
    "test_probabilities = model_for_eval.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(f\"‚úÖ Predictions completed!\")\n",
    "print(f\"Test set size: {len(test_predictions)}\")\n",
    "print(f\"Predicted survival rate: {test_predictions.mean():.3f}\")\n",
    "\n",
    "# Analyze predictions\n",
    "prediction_counts = pd.Series(test_predictions).value_counts().sort_index()\n",
    "print(f\"\\nPrediction Distribution:\")\n",
    "print(f\"  Not Survived (0): {prediction_counts[0]} ({prediction_counts[0]/len(test_predictions)*100:.1f}%)\")\n",
    "print(f\"  Survived (1): {prediction_counts[1]} ({prediction_counts[1]/len(test_predictions)*100:.1f}%)\")\n",
    "\n",
    "# Plot prediction distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(['Not Survived', 'Survived'], prediction_counts.values, color=['red', 'blue'], alpha=0.7)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Test Set Predictions Distribution')\n",
    "for i, v in enumerate(prediction_counts.values):\n",
    "    plt.text(i, v + 1, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(test_probabilities, bins=20, alpha=0.7, color='green', edgecolor='black')\n",
    "plt.xlabel('Predicted Probability of Survival')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Prediction Probability Distribution')\n",
    "plt.axvline(x=0.5, color='red', linestyle='--', label='Decision Threshold')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 18: Create Submission File\n",
    "# ================================================================================\n",
    "\n",
    "print(\"üìÑ CREATING SUBMISSION FILE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': passenger_ids,\n",
    "    'Survived': test_predictions\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission_filename = 'titanic_predictions.csv'\n",
    "submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"‚úÖ Submission file created: {submission_filename}\")\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "# Create detailed prediction file with probabilities\n",
    "detailed_submission = pd.DataFrame({\n",
    "    'PassengerId': passenger_ids,\n",
    "    'Survived': test_predictions,\n",
    "    'Survival_Probability': test_probabilities\n",
    "})\n",
    "\n",
    "detailed_filename = 'titanic_detailed_predictions.csv'\n",
    "detailed_submission.to_csv(detailed_filename, index=False)\n",
    "\n",
    "print(f\"‚úÖ Detailed submission file created: {detailed_filename}\")\n",
    "\n",
    "# Validation checks\n",
    "print(f\"\\nüîç SUBMISSION VALIDATION:\")\n",
    "print(f\"  PassengerId range: {submission['PassengerId'].min()} - {submission['PassengerId'].max()}\")\n",
    "print(f\"  Unique PassengerIds: {submission['PassengerId'].nunique()}\")\n",
    "print(f\"  Predictions are binary: {set(submission['Survived'].unique()) == {0, 1}}\")\n",
    "print(f\"  No missing values: {submission.isnull().sum().sum() == 0}\")\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 19: Model Interpretation and Insights\n",
    "# ================================================================================\n",
    "\n",
    "print(\"üß† MODEL INTERPRETATION AND INSIGHTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Key insights from the analysis\n",
    "print(\"KEY INSIGHTS FROM TITANIC SURVIVAL ANALYSIS:\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "print(\"\\n1. üìä FEATURE IMPORTANCE INSIGHTS:\")\n",
    "top_5_features = feature_importance.head(5)\n",
    "for idx, row in top_5_features.iterrows():\n",
    "    print(f\"   ‚Ä¢ {row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "print(f\"\\n2. üéØ MODEL PERFORMANCE:\")\n",
    "print(f\"   ‚Ä¢ Best Model: {best_model_name}\")\n",
    "print(f\"   ‚Ä¢ Cross-Validation Accuracy: {cv_scores_final.mean():.4f} ¬± {cv_scores_final.std():.4f}\")\n",
    "print(f\"   ‚Ä¢ Validation Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"   ‚Ä¢ ROC-AUC Score: {final_roc_auc:.4f}\")\n",
    "\n",
    "print(f\"\\n3. üìà SURVIVAL PREDICTIONS:\")\n",
    "print(f\"   ‚Ä¢ Training Set Survival Rate: {y_train.mean():.3f}\")\n",
    "print(f\"   ‚Ä¢ Test Set Predicted Survival Rate: {test_predictions.mean():.3f}\")\n",
    "print(f\"   ‚Ä¢ Model captures realistic survival patterns\")\n",
    "\n",
    "print(f\"\\n4. üîç KEY SURVIVAL FACTORS:\")\n",
    "print(f\"   ‚Ä¢ Gender appears to be the strongest predictor\")\n",
    "print(f\"   ‚Ä¢ Passenger class (socioeconomic status) is crucial\")\n",
    "print(f\"   ‚Ä¢ Age and family composition matter significantly\")\n",
    "print(f\"   ‚Ä¢ Fare and cabin location provide additional predictive power\")\n",
    "\n",
    "print(f\"\\n5. ‚öñÔ∏è MODEL RELIABILITY:\")\n",
    "if final_bias < 0.05 and final_variance < 0.05:\n",
    "    print(f\"   ‚Ä¢ Model shows good bias-variance balance\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ Model may need further tuning for optimal performance\")\n",
    "\n",
    "print(f\"   ‚Ä¢ Cross-validation shows consistent performance\")\n",
    "print(f\"   ‚Ä¢ Feature importance aligns with historical context\")\n",
    "\n",
    "# ================================================================================\n",
    "# CELL 20: Conclusion and Next Steps\n",
    "# ================================================================================\n",
    "\n",
    "print(\"üéâ PROJECT CONCLUSION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"MACHINE LEARNING PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"\\nüìã DELIVERABLES CREATED:\")\n",
    "print(f\"   ‚úÖ Trained and validated ML models\")\n",
    "print(f\"   ‚úÖ Feature importance analysis\")\n",
    "print(f\"   ‚úÖ Model performance evaluation\")\n",
    "print(f\"   ‚úÖ Test set predictions: {submission_filename}\")\n",
    "print(f\"   ‚úÖ Detailed predictions: {detailed_filename}\")\n",
    "\n",
    "print(f\"\\nüèÜ FINAL MODEL SUMMARY:\")\n",
    "print(f\"   Model Type: {best_model_name}\")\n",
    "print(f\"   Validation Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"   Cross-Validation: {cv_scores_final.mean():.4f} ¬± {cv_scores_final.std():.4f}\")\n",
    "print(f\"   ROC-AUC: {final_roc_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nüöÄ POTENTIAL IMPROVEMENTS:\")\n",
    "print(f\"   ‚Ä¢ Feature engineering: Extract more information from names, tickets\")\n",
    "print(f\"   ‚Ä¢ Advanced ensemble methods: Stacking, blending\")\n",
    "print(f\"   ‚Ä¢ Deep learning approaches for complex pattern detection\")\n",
    "print(f\"   ‚Ä¢ External data integration: Historical context, ship layout\")\n",
    "print(f\"   ‚Ä¢ Hyperparameter optimization with Bayesian methods\")\n",
    "\n",
    "print(f\"\\nüíº BUSINESS VALUE:\")\n",
    "print(f\"   ‚Ä¢ Demonstrates end-to-end ML pipeline capabilities\")\n",
    "print(f\"   ‚Ä¢ Shows proper model validation and evaluation practices\")\n",
    "print(f\"   ‚Ä¢ Provides interpretable insights for decision-making\")\n",
    "print(f\"   ‚Ä¢ Achieves competitive accuracy on benchmark dataset\")\n",
    "\n",
    "print(f\"\\n‚ú® This analysis demonstrates proficiency in:\")\n",
    "print(f\"   ‚Ä¢ Data preprocessing and feature engineering\")\n",
    "print(f\"   ‚Ä¢ Model selection and hyperparameter tuning\")\n",
    "print(f\"   ‚Ä¢ Cross-validation and performance evaluation\")\n",
    "print(f\"   ‚Ä¢ Model interpretation and business insights\")\n",
    "print(f\"   ‚Ä¢ Professional ML workflow and documentation\")\n",
    "\n",
    "print(f\"\\nüéØ Ready for deployment and real-world application!\")\n",
    "\n",
    "# Save model for future use (optional)\n",
    "import joblib\n",
    "\n",
    "model_filename = f'titanic_best_model_{best_model_name.lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")}.pkl'\n",
    "joblib.dump(model_for_eval, model_filename)\n",
    "print(f\"\\nüíæ Model saved as: {model_filename}\")\n",
    "\n",
    "# Save preprocessing pipeline\n",
    "preprocessing_pipeline = {\n",
    "    'scaler': scaler,\n",
    "    'feature_columns': X_train_scaled.columns.tolist(),\n",
    "    'categorical_features': categorical_features,\n",
    "    'numerical_features': numerical_features\n",
    "}\n",
    "\n",
    "pipeline_filename = 'titanic_preprocessing_pipeline.pkl'\n",
    "joblib.dump(preprocessing_pipeline, pipeline_filename)\n",
    "print(f\"üíæ Preprocessing pipeline saved as: {pipeline_filename}\")\n",
    "\n",
    "print(f\"\\nüéä MACHINE LEARNING ANALYSIS COMPLETE! üéä\")\\nüîÑ Tuning {model_name}...\")\n",
    "        \n",
    "        # Get base model\n",
    "        if model_name == 'Random Forest':\n",
    "            base_model = RandomForestClassifier(random_state=42)\n",
    "        elif model_name == 'Gradient Boosting':\n",
    "            base_model = GradientBoostingClassifier(random_state=42)\n",
    "        elif model_name == 'Logistic Regression':\n",
    "            base_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "        elif model_name == 'SVM':\n",
    "            base_model = SVC(random_state=42, probability=True)\n",
    "        \n",
    "        # Perform grid search\n",
    "        grid_search = GridSearchCV(\n",
    "            base_model,\n",
    "            param_grids[model_name],\n",
    "            cv=3,  # Reduced for faster execution\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train_final, y_train_final)\n",
    "        \n",
    "        # Store results\n",
    "        tuned_models[model_name] = grid_search.best_estimator_\n",
    "        \n",
    "        # Evaluate tuned model\n",
    "        y_val_pred_tuned = grid_search.best_estimator_.predict(X_val_final)\n",
    "        tuned_accuracy = accuracy_score(y_val_final, y_val_pred_tuned)\n",
    "        \n",
    "        tuning_results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Score (CV)': grid_search.best_score_,\n",
    "            'Validation Accuracy': tuned_accuracy,\n",
    "            'Best Parameters': grid_search.best_params_\n",
    "        })\n",
    "        \n",
    "        print(f\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
